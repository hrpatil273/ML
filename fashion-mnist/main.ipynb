{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c23186bf",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Machine Learning Algorithms for Fashion-MNIST Classification\n",
    "\n",
    "#### Team : Avinash Pawar, Aoi Minamoto, Harshwardhan Patil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ce90986",
   "metadata": {},
   "source": [
    "#### In this part we will test different classification methodologies and test them against different hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0a3c2db",
   "metadata": {},
   "source": [
    "First of all we will import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53025b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6154b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training and testing data\n",
    "train_data = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c35748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and test labels \n",
    "train_labels = train_data['label']\n",
    "test_labels = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping label column from the datasets\n",
    "train_data.drop(columns=['label'], axis = 1, inplace = True)\n",
    "test_data.drop(columns=['label'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=10000, random_state=42)\n",
    "# Split the dataset into training and validation data sets\n",
    "for train_index, val_index in split.split(train_data, train_labels):\n",
    "    train_dataset_ = train_data.loc[train_index]\n",
    "    labels_train_dataset = train_labels.loc[train_index]\n",
    "    \n",
    "    validation_dataset_ = train_data.loc[val_index]\n",
    "    labels_validation_dataset = train_labels.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_.shape, labels_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_.shape, labels_validation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d90b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot digits into an image format\n",
    "def plot_data(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "for index_i, image_data in enumerate(train_dataset_.values[:100]):\n",
    "    plt.subplot(10, 10, index_i + 1)\n",
    "    plot_data(image_data)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7badb193",
   "metadata": {},
   "source": [
    "# Implementing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.96)\n",
    "pca.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and testing data using PCA\n",
    "train_dataset = pd.DataFrame(pca.transform(train_dataset_))\n",
    "validation_dataset = pd.DataFrame(pca.transform(validation_dataset_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shape, validation_dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83c36407",
   "metadata": {},
   "source": [
    "It looks like the features are reduced to 226. Let's use the next possible square value, i.e. 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)\n",
    "pca.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed331cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and testing data using PCA\n",
    "train_dataset = pd.DataFrame(pca.transform(train_dataset_))\n",
    "validation_dataset = pd.DataFrame(pca.transform(validation_dataset_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and testing data using PCA\n",
    "train_data = pd.DataFrame(pca.transform(train_data))\n",
    "test_data = pd.DataFrame(pca.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shape, validation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16873e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_recovered = pd.DataFrame(pca.inverse_transform(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot digits into an image format\n",
    "def plot_transformed_digit(image_data):\n",
    "    image = image_data.reshape(28,28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "for index_i, image_data in enumerate(train_dataset_recovered.values[:100]):\n",
    "    plt.subplot(10, 10, index_i + 1)\n",
    "    plot_transformed_digit(image_data)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data.values[:1000])\n",
    "test_data = pd.DataFrame(test_data.values[:1000])\n",
    "\n",
    "train_labels = pd.DataFrame(train_labels.values[:1000])\n",
    "test_labels = pd.DataFrame(test_labels.values[:1000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f2f3b4e",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b948869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11876390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameter values\n",
    "C_values = [1, 2, 3, 4, 5, 10]\n",
    "penalty_values = ['l1', 'l2']\n",
    "l_p, l_c = len(penalty_values), len(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, validation_accuracy = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_precision, validation_precision = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_recall, validation_recall = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_f1_score, validation_f1_score = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_i, penalty in enumerate(penalty_values):\n",
    "    for index_j, C in enumerate(C_values):     \n",
    "        logistic_reg_model = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty=penalty, n_jobs= -1)\n",
    "        \n",
    "        # Fit model on training data\n",
    "        logistic_reg_model.fit(train_dataset, labels_train_dataset)\n",
    "        \n",
    "        # Predicting training labels based on trainig data\n",
    "        training_labels_pred = logistic_reg_model.predict(train_dataset)\n",
    "        \n",
    "        # Predicting validation labels based on validation data\n",
    "        validation_labels_pred = logistic_reg_model.predict(validation_dataset)\n",
    "        \n",
    "        # calculating scores on training dataset\n",
    "        training_precision[index_i][index_j]=precision_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_accuracy[index_i][index_j]=accuracy_score(labels_train_dataset, training_labels_pred)\n",
    "        training_recall[index_i][index_j]=recall_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_f1_score[index_i][index_j]=f1_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        \n",
    "        # calculating scores on validation dataset\n",
    "        validation_precision[index_i][index_j]=precision_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_accuracy[index_i][index_j]=accuracy_score(labels_validation_dataset, validation_labels_pred)\n",
    "        validation_recall[index_i][index_j]=recall_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_f1_score[index_i][index_j]=f1_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        \n",
    "        # Keep track of best hyperparameters and corresponding validation accuracy\n",
    "        if validation_accuracy[index_i][index_j] > best_accuracy:\n",
    "            best_accuracy = validation_accuracy[index_i][index_j]\n",
    "            best_parameters = {'penalty': penalty, 'C': C}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7e8f6ef",
   "metadata": {},
   "source": [
    "#### Printing calculated scores on training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b427ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Logistic Regression Model:\")\n",
    "for index_i, penalty in enumerate(penalty_values):\n",
    "    for index_j, C in enumerate(C_values):   \n",
    "        print(f\"\\t  With penalty {penalty} and regularization parameter: {C}\")\n",
    "        print('\\t\\t  Accuracy Score: ', validation_accuracy[index_i][index_j])\n",
    "        print('\\t\\t  Precision Score:', validation_precision[index_i][index_j])\n",
    "        print('\\t\\t  Recall Score:', validation_recall[index_i][index_j])\n",
    "        print('\\t\\t  F1 Score:', validation_f1_score[index_i][index_j])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c31832fb",
   "metadata": {},
   "source": [
    "#### Plotting validation curve with training accuracy and validation accuracy as function of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80678d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = C_values\n",
    "\n",
    "train_acc_l1 = training_accuracy[0]\n",
    "val_acc_l1 = validation_accuracy[0]\n",
    "\n",
    "train_acc_l2 = training_accuracy[1]\n",
    "val_acc_l2 = validation_accuracy[1]\n",
    "\n",
    "plt.plot(C_values, train_acc_l1, marker='o', linestyle='--', color='r', linewidth=4, label='Training Accuracy with L1 penalty')\n",
    "plt.plot(C_values, val_acc_l1, marker='o', linestyle='--', color='g', linewidth=4,  label='Validation Accuracy with L1 penalty')\n",
    "\n",
    "\n",
    "plt.plot(C_values, train_acc_l2, marker='o', linestyle='-', color='c', linewidth=4, label='Training Accuracy with L2 penalty')\n",
    "plt.plot(C_values, val_acc_l2, marker='o', linestyle='-', color='m', linewidth=4,  label='Validation Accuracy with L2 penalty')\n",
    "\n",
    "plt.title('Training and validation accuracy a function of regularization parameters', size=10)\n",
    "plt.xlabel('Regularization Parameters')\n",
    "plt.ylabel('Accuracy' )\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22355595",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(12, 10))\n",
    "\n",
    "x = C_values\n",
    "\n",
    "train_acc_l1 = training_accuracy[0]\n",
    "val_acc_l1 = validation_accuracy[0]\n",
    "\n",
    "train_acc_l2 = training_accuracy[1]\n",
    "val_acc_l2 = validation_accuracy[1]\n",
    "\n",
    "ax[0][0].plot(C_values, train_acc_l1, marker='.', linestyle='--', color='r')\n",
    "ax[0][0].set_title('Training Accuracy with L1 penalty', size=10)\n",
    "ax[0][0].set_xlabel('Regularization Parameters')\n",
    "ax[0][0].set_ylabel('Accuracy')\n",
    "\n",
    "ax[0][1].plot(C_values, train_acc_l2, marker='.', linestyle='-', color='g', label='Training Accuracy with L2 penalty')\n",
    "ax[0][1].set_title('Training Accuracy with L2 penalty', size=10)\n",
    "ax[0][1].set_xlabel('Regularization Parameters')\n",
    "ax[0][1].set_ylabel('Accuracy')\n",
    "\n",
    "ax[1][0].plot(C_values, val_acc_l1, marker='.', linestyle='--', color='r', label='Validation Accuracy with L1 penalty')\n",
    "ax[1][0].set_title('Validation Accuracy with L1 penalty', size=10)\n",
    "ax[1][0].set_xlabel('Regularization Parameters')\n",
    "ax[1][0].set_ylabel('Accuracy')\n",
    "\n",
    "ax[1][1].plot(C_values, val_acc_l2, marker='.', linestyle='-', color='g', label='Validation Accuracy with L2 penalty')\n",
    "ax[1][1].set_title('Validation Accuracy with L2 penalty', size=10)\n",
    "ax[1][1].set_xlabel('Regularization Parameters')\n",
    "ax[1][1].set_ylabel('Accuracy')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d263a714",
   "metadata": {},
   "source": [
    "### Now, we will test the model on the best hyperparameters we got from above processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7db7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_parameters)\n",
    "print(\"Model accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db52d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameters for executing it on test data\n",
    "logistic_reg_model = LogisticRegression(multi_class='multinomial', solver='saga', C=MLR_parameters['C'], penalty=MLR_parameters['penalty'], n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a00f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data labels based on trained model\n",
    "test_labels_pred = logistic_reg_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2393049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "plt.rc('font', size=10)  \n",
    "cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb1b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e23f7ec",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02998845",
   "metadata": {},
   "source": [
    "## 1. Using Linear Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66715b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ece92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameter values\n",
    "C_values = [1, 2, 3, 4, 5, 10]\n",
    "l_c = len(C_values)\n",
    "l_p =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, validation_accuracy = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_precision, validation_precision = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_recall, validation_recall = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))\n",
    "training_f1_score, validation_f1_score = np.zeros((l_p, l_c)) ,  np.zeros((l_p, l_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78253be",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ed270",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_i = 0\n",
    "for index_j, C in enumerate(C_values):   \n",
    "    # initialize the model\n",
    "    svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=C, random_state=42,cache_size=8000))\n",
    "    # Fit model on training data\n",
    "    svm_model.fit(train_dataset, labels_train_dataset)\n",
    "\n",
    "    # Predicting training labels based on trainig data\n",
    "    training_labels_pred = svm_model.predict(train_dataset)\n",
    "\n",
    "    # Predicting validation labels based on validation data\n",
    "    validation_labels_pred = svm_model.predict(validation_dataset)\n",
    "    \n",
    "    # calculating scores on training dataset\n",
    "    training_precision[index_i][index_j]=precision_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "    training_accuracy[index_i][index_j]=accuracy_score(labels_train_dataset, training_labels_pred)\n",
    "    training_recall[index_i][index_j]=recall_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "    training_f1_score[index_i][index_j]=f1_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "\n",
    "    # calculating scores on validation dataset\n",
    "    validation_precision[index_i][index_j]=precision_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "    validation_accuracy[index_i][index_j]=accuracy_score(labels_validation_dataset, validation_labels_pred)\n",
    "    validation_recall[index_i][index_j]=recall_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "    validation_f1_score[index_i][index_j]=f1_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "\n",
    "    # Keep track of best hyperparameters and corresponding validation accuracy\n",
    "    if validation_accuracy[index_i][index_j] > best_accuracy:\n",
    "        best_accuracy = validation_accuracy[index_i][index_j]\n",
    "        best_parameters = {'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c398f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For SVM model with linear kernal:\")\n",
    "index_i=0\n",
    "for index_j, C in enumerate(C_values):   \n",
    "    print(f\"\\t  With regularization parameter: {C}\")\n",
    "    print('\\t\\t  Accuracy Score: ', validation_accuracy[index_i][index_j])\n",
    "    print('\\t\\t  Precision Score:', validation_precision[index_i][index_j])\n",
    "    print('\\t\\t  Recall Score:', validation_recall[index_i][index_j])\n",
    "    print('\\t\\t  F1 Score:', validation_f1_score[index_i][index_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 10))\n",
    "\n",
    "train_acc = training_accuracy[0]\n",
    "val_acc = validation_accuracy[0]\n",
    "\n",
    "ax[0].plot(C_values, train_acc, marker='.', linestyle='--', color='r')\n",
    "ax[0].set_title('Training Accuracy', size=10)\n",
    "ax[0].set_xlabel('Regularization Parameters')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "ax[1].plot(C_values, val_acc, marker='.', linestyle='-', color='g')\n",
    "ax[1].set_title('Validation Accuracy', size=10)\n",
    "ax[1].set_xlabel('Regularization Parameters')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c616720",
   "metadata": {},
   "source": [
    "### Now, we will test the model on the best hyperparameters we got from above processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d32d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_linear_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_parameters)\n",
    "print(\"Model accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=SVM_linear_parameters['C'], random_state=42,cache_size=8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data labels based on trained model\n",
    "test_labels_pred = svm_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "plt.rc('font', size=10)  \n",
    "cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1535eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898a796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d57bd427",
   "metadata": {},
   "source": [
    "## 2. Using Polynomial Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ab0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameter values\n",
    "C_values = [1, 2, 3, 4, 5, 10]\n",
    "coefficients  = [0, 1, 2]\n",
    "l_coe, l_c = len(coefficients), len(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, validation_accuracy = np.zeros((l_coe, l_c)) ,  np.zeros((l_coe, l_c))\n",
    "training_precision, validation_precision = np.zeros((l_coe, l_c)) ,  np.zeros((l_coe, l_c))\n",
    "training_recall, validation_recall = np.zeros((l_coe, l_c)) ,  np.zeros((l_coe, l_c))\n",
    "training_f1_score, validation_f1_score = np.zeros((l_coe, l_c)) ,  np.zeros((l_coe, l_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a51a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_i, coef in enumerate(coefficients):\n",
    "    for index_j, C in enumerate(C_values):     \n",
    "        #initialize the model\n",
    "        svm_poly = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3, random_state=42,cache_size=8000))\n",
    "        \n",
    "        # set the parameters\n",
    "        svm_poly.set_params(svc__C=C, svc__coef0=coef)\n",
    "        \n",
    "        # Fit model on training data\n",
    "        svm_poly.fit(train_dataset, labels_train_dataset)\n",
    "        \n",
    "        # Predicting training labels based on trainig data\n",
    "        training_labels_pred = svm_poly.predict(train_dataset)\n",
    "        \n",
    "        # Predicting validation labels based on validation data\n",
    "        validation_labels_pred = svm_poly.predict(validation_dataset)\n",
    "        \n",
    "        # calculating scores on training dataset\n",
    "        training_precision[index_i][index_j]=precision_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_accuracy[index_i][index_j]=accuracy_score(labels_train_dataset, training_labels_pred)\n",
    "        training_recall[index_i][index_j]=recall_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_f1_score[index_i][index_j]=f1_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        \n",
    "        # calculating scores on validation dataset\n",
    "        validation_precision[index_i][index_j]=precision_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_accuracy[index_i][index_j]=accuracy_score(labels_validation_dataset, validation_labels_pred)\n",
    "        validation_recall[index_i][index_j]=recall_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_f1_score[index_i][index_j]=f1_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        \n",
    "        # Keep track of best hyperparameters and corresponding validation accuracy\n",
    "        if validation_accuracy[index_i][index_j] > best_accuracy:\n",
    "            best_accuracy = validation_accuracy[index_i][index_j]\n",
    "            best_parameters = {'coefficients': coef, 'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965877d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For SVM with polynomial kernal Model:\")\n",
    "for index_i, coef in enumerate(coefficients):\n",
    "    for index_j, C in enumerate(C_values):   \n",
    "        print(f\"\\t  With coefficient {coef} and regularization parameter: {C}\")\n",
    "        print('\\t\\t  Accuracy Score: ', validation_accuracy[index_i][index_j])\n",
    "        print('\\t\\t  Precision Score:', validation_precision[index_i][index_j])\n",
    "        print('\\t\\t  Recall Score:', validation_recall[index_i][index_j])\n",
    "        print('\\t\\t  F1 Score:', validation_f1_score[index_i][index_j])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15dd139c",
   "metadata": {},
   "source": [
    "#### Plotting validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb284380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=len(coefficients), ncols=1, figsize=(12, 10))\n",
    "\n",
    "# Flatten the axs array to simplify the loop\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over the subplots and plot the data\n",
    "# coefficient * c_values\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.plot(C_values, training_accuracy[i], marker='.', linestyle='--', color='r', label = \"Training Accuracy\")\n",
    "    ax.plot(C_values, validation_accuracy[i], marker='.', linestyle='-', color='g', label = \"Validation Accuracy\")\n",
    "    # Set the title, xlabel, ylabel, and legend for each subplot\n",
    "    ax.set_title(f'Training and validation accuracy for parameter coef0 ={coefficients[i]} as a function of regularization parameters')\n",
    "    ax.set_xlabel('Regularization Parameters')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c5b835f",
   "metadata": {},
   "source": [
    "### Now, we will test the model on the best hyperparameters we got from above processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a551ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_poly_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5181d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_parameters)\n",
    "print(\"Model accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b596ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameters for executing it on test data\n",
    "svm_poly = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3, random_state=42,cache_size=8000))\n",
    "svm_poly.set_params(svc__C=SVM_poly_parameters['C'], svc__coef0=SVM_poly_parameters['coefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfdeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data labels based on trained model\n",
    "test_labels_pred = svm_poly.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbedef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "plt.rc('font', size=10)  \n",
    "cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86705a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f6233f4",
   "metadata": {},
   "source": [
    "## 3. Using RBF Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1814fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameter values\n",
    "C_values = [1, 2, 3, 4, 5, 10]\n",
    "gammas  = [0.1, 1, 10]\n",
    "l_g, l_c = len(gammas), len(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd846cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, validation_accuracy = np.zeros((l_g, l_c)) ,  np.zeros((l_g, l_c))\n",
    "training_precision, validation_precision = np.zeros((l_g, l_c)) ,  np.zeros((l_g, l_c))\n",
    "training_recall, validation_recall = np.zeros((l_g, l_c)) ,  np.zeros((l_g, l_c))\n",
    "training_f1_score, validation_f1_score = np.zeros((l_g, l_c)) ,  np.zeros((l_g, l_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48634271",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_i, gamma in enumerate(gammas):\n",
    "    for index_j, C in enumerate(C_values):     \n",
    "        \n",
    "        svm_rbf = SVC(kernel='rbf', C=C, gamma=gamma,cache_size=8000)\n",
    "        \n",
    "        # Fit model on training data\n",
    "        svm_rbf.fit(train_dataset, labels_train_dataset)\n",
    "        \n",
    "        # Predicting training labels based on trainig data\n",
    "        training_labels_pred = svm_rbf.predict(train_dataset)\n",
    "        \n",
    "        # Predicting validation labels based on validation data\n",
    "        validation_labels_pred = svm_rbf.predict(validation_dataset)\n",
    "        \n",
    "        # calculating scores on training dataset\n",
    "        training_precision[index_i][index_j]=precision_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_accuracy[index_i][index_j]=accuracy_score(labels_train_dataset, training_labels_pred)\n",
    "        training_recall[index_i][index_j]=recall_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_f1_score[index_i][index_j]=f1_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        \n",
    "        # calculating scores on validation dataset\n",
    "        validation_precision[index_i][index_j]=precision_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_accuracy[index_i][index_j]=accuracy_score(labels_validation_dataset, validation_labels_pred)\n",
    "        validation_recall[index_i][index_j]=recall_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_f1_score[index_i][index_j]=f1_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        \n",
    "        # Keep track of best hyperparameters and corresponding validation accuracy\n",
    "        if validation_accuracy[index_i][index_j] > best_accuracy:\n",
    "            best_accuracy = validation_accuracy[index_i][index_j]\n",
    "            best_parameters = {'gamma': gamma, 'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For SVM with RBF kernal Model:\")\n",
    "for index_i, gamma in enumerate(gammas):\n",
    "    for index_j, C in enumerate(C_values): \n",
    "        print(f\"\\t  With Gamma: {gamma} and regularization parameter: {C}\")\n",
    "        print('\\t\\t  Accuracy Score: ', validation_accuracy[index_i][index_j])\n",
    "        print('\\t\\t  Precision Score:', validation_precision[index_i][index_j])\n",
    "        print('\\t\\t  Recall Score:', validation_recall[index_i][index_j])\n",
    "        print('\\t\\t  F1 Score:', validation_f1_score[index_i][index_j])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2235413",
   "metadata": {},
   "source": [
    "#### Plotting validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94595c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [1, 2, 3, 4, 5, 10]\n",
    "gammas  = [1, 2, 5, 10]\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=len(gammas), ncols=1, figsize=(12, 10))\n",
    "\n",
    "# Flatten the axs array to simplify the loop\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over the subplots and plot the data\n",
    "# gammas * c_values\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.plot(C_values, training_accuracy[i], marker='.', linestyle='--', color='r', label = \"Training Accuracy\")\n",
    "    ax.plot(C_values, validation_accuracy[i], marker='.', linestyle='-', color='g', label = \"Validation Accuracy\")\n",
    "    # Set the title, xlabel, ylabel, and legend for each subplot\n",
    "    ax.set_title(f'Training and validation accuracy for parameter Gamma ={gammas[i]} as a function of regularization parameters')\n",
    "    ax.set_xlabel('Regularization Parameters')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03e4c5c8",
   "metadata": {},
   "source": [
    "### Now, we will test the model on the best hyperparameters we got from above processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_rbf_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_parameters)\n",
    "print(\"Model accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameters for executing it on test data\n",
    "svm_rbf = SVC(kernel='rbf', C=SVM_rbf_parameters['C'], gamma=SVM_rbf_parameters['gamma'],cache_size=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98089d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data labels based on trained model\n",
    "test_labels_pred = svm_rbf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "plt.rc('font', size=10)  \n",
    "cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728c44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17ceccf4",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c93699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameter values\n",
    "estimators = [50, 100, 200, 500, 1000]\n",
    "depths  = [5, 10, 50]\n",
    "l_e, l_d = len(estimators), len(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, validation_accuracy = np.zeros((l_e, l_d)) ,  np.zeros((l_e, l_d))\n",
    "training_precision, validation_precision = np.zeros((l_e, l_d)) ,  np.zeros((l_e, l_d))\n",
    "training_recall, validation_recall = np.zeros((l_e, l_d)) ,  np.zeros((l_e, l_d))\n",
    "training_f1_score, validation_f1_score = np.zeros((l_e, l_d)) ,  np.zeros((l_e, l_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df52536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_i, estimator in enumerate(estimators):\n",
    "    for index_j, depth in enumerate(depths):    \n",
    "        \n",
    "        rfc = RandomForestClassifier(n_estimators=estimator, max_depth=depth, n_jobs= -1)\n",
    "        # Fit model on training data\n",
    "        rfc.fit(train_dataset, labels_train_dataset)\n",
    "        \n",
    "        # Predicting training labels based on trainig data\n",
    "        training_labels_pred = rfc.predict(train_dataset)\n",
    "        \n",
    "        # Predicting validation labels based on validation data\n",
    "        validation_labels_pred = rfc.predict(validation_dataset)\n",
    "        \n",
    "        # calculating scores on training dataset\n",
    "        training_precision[index_i][index_j]=precision_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_accuracy[index_i][index_j]=accuracy_score(labels_train_dataset, training_labels_pred)\n",
    "        training_recall[index_i][index_j]=recall_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        training_f1_score[index_i][index_j]=f1_score(labels_train_dataset, training_labels_pred, average='weighted')\n",
    "        \n",
    "        # calculating scores on validation dataset\n",
    "        validation_precision[index_i][index_j]=precision_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_accuracy[index_i][index_j]=accuracy_score(labels_validation_dataset, validation_labels_pred)\n",
    "        validation_recall[index_i][index_j]=recall_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        validation_f1_score[index_i][index_j]=f1_score(labels_validation_dataset, validation_labels_pred, average='weighted')\n",
    "        \n",
    "        # Keep track of best hyperparameters and corresponding validation accuracy\n",
    "        if validation_accuracy[index_i][index_j] > best_accuracy:\n",
    "            best_accuracy = validation_accuracy[index_i][index_j]\n",
    "            best_parameters = {'n_estimators': estimator, 'max_depth': depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b410b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Random Forest Classifier Model:\")\n",
    "for index_i, estimator in enumerate(estimators):\n",
    "    for index_j, depth in enumerate(depths):  \n",
    "        print(f\"\\t  With Estimators: {estimator} and Depth: {depth}\")\n",
    "        print('\\t\\t  Accuracy Score: ', validation_accuracy[index_i][index_j])\n",
    "        print('\\t\\t  Precision Score:', validation_precision[index_i][index_j])\n",
    "        print('\\t\\t  Recall Score:', validation_recall[index_i][index_j])\n",
    "        print('\\t\\t  F1 Score:', validation_f1_score[index_i][index_j])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d19458f",
   "metadata": {},
   "source": [
    "#### Plotting validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [50, 100, 200, 500, 1000]\n",
    "depths  = [5, 10, 50]\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=len(depths), ncols=1, figsize=(12, 10))\n",
    "\n",
    "# Flatten the axs array to simplify the loop\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over the subplots and plot the data\n",
    "# coefficient * c_values\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.plot(np.log(estimators), training_accuracy[i], marker='.', linestyle='--', color='r', label = \"Training Accuracy\")\n",
    "    ax.plot(np.log(estimators), validation_accuracy[i], marker='.', linestyle='-', color='g', label = \"Validation Accuracy\")\n",
    "    # Set the title, xlabel, ylabel, and legend for each subplot\n",
    "    ax.set_title(f'Training and validation accuracy for parameter depth ={depths[i]} as a function of log estimators')\n",
    "    ax.set_xlabel('Regularization Parameters')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45a36943",
   "metadata": {},
   "source": [
    "### Now, we will test the model on the best hyperparameters we got from above processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d968c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_parameters = best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_parameters)\n",
    "print(\"Model accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ea15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with best hyperparameters for executing it on test data\n",
    "rfc = RandomForestClassifier(n_estimators=rfc_parameters['n_estimators'], max_depth=rfc_parameters['max_depth'], n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d150d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data labels based on trained model\n",
    "test_labels_pred = rfc.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8416c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "plt.rc('font', size=10)  \n",
    "cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def33e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1788351",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28aa935d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72d1eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=rfc_parameters['n_estimators'], \n",
    "                             max_depth=rfc_parameters['max_depth'], \n",
    "                             min_samples_leaf = rfc_parameters['min_samples_leaf'], \n",
    "                             min_samples_split = rfc_parameters['min_samples_split'], \n",
    "                             n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2aaf4ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, n_jobs=-1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85e4892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features and their importances for Hard Voting Classifier:\n",
      "1: 0.0738\n",
      "0: 0.0580\n",
      "2: 0.0568\n",
      "5: 0.0485\n",
      "4: 0.0401\n",
      "7: 0.0338\n",
      "6: 0.0322\n",
      "3: 0.0320\n",
      "8: 0.0227\n",
      "9: 0.0213\n"
     ]
    }
   ],
   "source": [
    "important_features = rfc_model.feature_importances_\n",
    "\n",
    "# Get the indices of the top 10 features\n",
    "feature_indices = np.argsort(important_features)[::-1][:10]\n",
    "\n",
    "# Print the top 10 features and their importances\n",
    "print(\"Top 10 features and their importances for Hard Voting Classifier:\")\n",
    "for index_i in feature_indices:\n",
    "    print(\"{}: {:.4f}\".format(index_i, important_features[index_i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bed8f51",
   "metadata": {},
   "source": [
    "we will plot the heatmap for viewing important pixels in the image, which potentially can be used for training the data more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbec1950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(rfc_model.feature_importances_.reshape(16,16), cmap = 'hot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c632d81f",
   "metadata": {},
   "source": [
    "We can have a look at the transformed data to get better understanding about what the plot is suggesting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67cf9232",
   "metadata": {},
   "source": [
    "# Ensamble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Classifier object\n",
    "logistic_reg_model = LogisticRegression(multi_class='multinomial', solver='saga', C=MLR_parameters['C'], penalty=MLR_parameters['penalty'], n_jobs= -1)\n",
    "\n",
    "# Create a SVM Classifier object\n",
    "svm_rbf = SVC(kernel='rbf', C=SVM_rbf_parameters['C'], gamma=SVM_rbf_parameters['gamma'],cache_size=8000)\n",
    "\n",
    "# Create a Random Forest Classifier object\n",
    "rfc = RandomForestClassifier(n_estimators=rfc_parameters['n_estimators'], max_depth=rfc_parameters['max_depth'], n_jobs= -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca4d5050",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ceca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble of the three classifiers\n",
    "voting_classifier = VotingClassifier(estimators=[('logistic_regression', logistic_reg_model), \n",
    "                                                 ('svm', svm_rbf), ('randomforest', rfc)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58775383",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7194e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_pred = voting_classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586db631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.rc('font', size=10)  # extra code  make the text smaller\n",
    "ConfusionMatrixDisplay.from_predictions(test_labels, test_labels_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e64da2f",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = rf.feature_importances_\n",
    "\n",
    "# Get the indices of the top 10 features\n",
    "feature_indices = np.argsort(important_features)[::-1][:10]\n",
    "\n",
    "# Print the top 10 features and their importances\n",
    "print(\"Top 10 features and their importances for Hard Voting Classifier:\")\n",
    "for index_i in feature_indices:\n",
    "    print(\"{}: {:.4f}\".format(index_i, important_features[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dd57d4d",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble of the three classifiers\n",
    "voting_classifier = VotingClassifier(estimators=[('logistic_regression', logistic_reg_model), \n",
    "                                                 ('svm', svm_rbf), ('randomforest', rfc)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad84a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_pred = voting_classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa23ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.rc('font', size=10)  # extra code  make the text smaller\n",
    "ConfusionMatrixDisplay.from_predictions(test_labels, test_labels_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ',precision_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('Precision Score:',accuracy_score(test_labels, test_labels_pred))\n",
    "print('Recall Score:',recall_score(test_labels, test_labels_pred, average='weighted'))\n",
    "print('F1 Score:',f1_score(test_labels, test_labels_pred, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb409ce6",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = rf.feature_importances_\n",
    "\n",
    "# Get the indices of the top 10 features\n",
    "feature_indices = np.argsort(important_features)[::-1][:10]\n",
    "\n",
    "# Print the top 10 features and their importances\n",
    "print(\"Top 10 features and their importances for Soft Voting Classifier:\")\n",
    "for index_i in feature_indices:\n",
    "    print(\"{}: {:.4f}\".format(index_i, important_features[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
